Task 6: K-Nearest Neighbors (KNN)
Objective:
To implement the KNN algorithm for classification and understand how it makes predictions based on data proximity.

What I Did:
Loaded and preprocessed a suitable classification dataset
Trained a KNN classifier using Scikit-learn
Experimented with different values of k (number of neighbors)
Used accuracy score, confusion matrix, and classification report to evaluate performance
Visualized how changing k affects model behavior

Libraries Used:
Pandas
NumPy
Scikit-learn
Matplotlib / Seaborn (for plots)

Key Concepts I Learned:
How KNN works based on the similarity (distance) between data points
The impact of choosing a small or large value for k
The importance of feature scaling when using distance-based algorithms
When KNN is useful (non-parametric, no training phase)

Output:
A working KNN model that classifies data based on neighbors, and an understanding of how distance and neighborhood size affect results.
